# Spark Cluster

:::: {tab-set}

::: {tab-item} 3.5.0

[![](badges/release-3.5.0-blue.svg)](https://cloud.sdu.dk/app/jobs/create?app=spark-cluster&version=3.5.0)
[![type](badges/type-interactive-yellow.svg)](interactive_apps.md)
![access](badges/access-open-green.svg)
* **Operating System:** ![](./badges/Ubuntu-22.04-lightseagreen.svg)
* **Terminal:** ![](./badges/tini-0.19.0-lightseagreen.svg) ![](./badges/tmux-3.2a-lightseagreen.svg)
* **Shell:** ![](./badges/bash-5.1.16-lightseagreen.svg) ![](./badges/fish-3.3.1-lightseagreen.svg) ![](./badges/zsh-5.8.1-lightseagreen.svg)
* **Editor:** ![](./badges/emacs-27.1-lightseagreen.svg) ![](./badges/nano-6.2-lightseagreen.svg) ![](./badges/vim-8.2-lightseagreen.svg)
* **Package Manager:** ![](./badges/apt-2.4.10-lightseagreen.svg) ![](./badges/conda-23.3.1-lightseagreen.svg) ![](./badges/dpkg-1.21.1-lightseagreen.svg) ![](./badges/npm-8.5.1-lightseagreen.svg) ![](./badges/pip-23.2.1-lightseagreen.svg)
* **Programming Language:** ![](./badges/GCC-11.4.0-lightseagreen.svg) ![](./badges/OpenJDK-11.0.20.1-lightseagreen.svg) ![](./badges/Python-3.10.12-lightseagreen.svg) ![](./badges/Python-2.7.18-lightseagreen.svg) ![](./badges/R-4.3.1-lightseagreen.svg)
* **Database:** ![](./badges/SQLite-3.37.2-lightseagreen.svg)
* **Utility:** ![](./badges/EasyBuild-4.8.0-lightseagreen.svg) ![](./badges/Lmod-8.7-lightseagreen.svg)
* **Extension:** ![](./badges/Apache-Spark-3.5.0-lightseagreen.svg) ![](./badges/OpenMPI-4.1.2-lightseagreen.svg)

:::

::: {tab-item} 3.4.1

[![](badges/release-3.4.1-blue.svg)](https://cloud.sdu.dk/app/jobs/create?app=spark-cluster&version=3.4.1)
[![type](badges/type-interactive-yellow.svg)](interactive_apps.md)
![access](badges/access-open-green.svg)
* **Operating System:** ![](./badges/Ubuntu-22.10-lightseagreen.svg)
* **Terminal:** ![](./badges/tini-0.19.0-lightseagreen.svg) ![](./badges/tmux-3.3a-lightseagreen.svg)
* **Shell:** ![](./badges/bash-5.2.2-lightseagreen.svg) ![](./badges/fish-3.5.1-lightseagreen.svg) ![](./badges/zsh-5.9-lightseagreen.svg)
* **Editor:** ![](./badges/emacs-27.1-lightseagreen.svg) ![](./badges/nano-6.4-lightseagreen.svg) ![](./badges/vim-9.0-lightseagreen.svg)
* **Package Manager:** ![](./badges/apt-2.5.3-lightseagreen.svg) ![](./badges/conda-23.1.0-lightseagreen.svg) ![](./badges/dpkg-1.21.9-lightseagreen.svg) ![](./badges/npm-8.18.0-lightseagreen.svg) ![](./badges/pip-23.0.1-lightseagreen.svg)
* **Programming Language:** ![](./badges/GCC-12.2.0-lightseagreen.svg) ![](./badges/OpenJDK-11.0.19-lightseagreen.svg) ![](./badges/Python-3.10.10-lightseagreen.svg) ![](./badges/Python-2.7.18-lightseagreen.svg) ![](./badges/R-4.2.3-lightseagreen.svg)
* **Database:** ![](./badges/SQLite-3.39.3-lightseagreen.svg)
* **Utility:** ![](./badges/Lmod-8.7-lightseagreen.svg)
* **Extension:** ![](./badges/Apache-Spark-3.4.1-lightseagreen.svg) ![](./badges/OpenMPI-4.1.4-lightseagreen.svg)

:::

::: {tab-item} 3.3.2

[![](badges/release-3.3.2-blue.svg)](https://cloud.sdu.dk/app/jobs/create?app=spark-cluster&version=3.3.2)
[![type](badges/type-interactive-yellow.svg)](interactive_apps.md)
![access](badges/access-open-green.svg)
* **Operating System:** ![](./badges/Ubuntu-22.10-lightseagreen.svg)
* **Shell:** ![](./badges/bash-5.2.2-lightseagreen.svg)
* **Editor:** ![](./badges/emacs-27.1-lightseagreen.svg) ![](./badges/nano-6.4-lightseagreen.svg) ![](./badges/vim-9.0-lightseagreen.svg)
* **Package Manager:** ![](./badges/apt-2.5.3-lightseagreen.svg) ![](./badges/conda-22.11.1-lightseagreen.svg) ![](./badges/dpkg-1.21.9-lightseagreen.svg) ![](./badges/npm-8.18.0-lightseagreen.svg) ![](./badges/pip-23.0.1-lightseagreen.svg)
* **Programming Language:** ![](./badges/GCC-12.2.0-lightseagreen.svg) ![](./badges/OpenJDK-1.8.0-lightseagreen.svg) ![](./badges/Python-3.10.9-lightseagreen.svg) ![](./badges/Python-2.7.18-lightseagreen.svg) ![](./badges/R-4.2.2-lightseagreen.svg) ![](./badges/Scala-2.12.15-lightseagreen.svg)
* **Database:** ![](./badges/SQLite-3.39.3-lightseagreen.svg)

:::

::: {tab-item} 3.2.2

[![](badges/release-3.2.2-blue.svg)](https://cloud.sdu.dk/app/jobs/create?app=spark-cluster&version=3.2.2)
[![type](badges/type-interactive-yellow.svg)](interactive_apps.md)
![access](badges/access-open-green.svg)
* **Operating System:** ![](./badges/Ubuntu-20.04-lightseagreen.svg)
* **Shell:** ![](./badges/bash-5.0.17-lightseagreen.svg)
* **Editor:** ![](./badges/emacs-26.3-lightseagreen.svg) ![](./badges/nano-4.8-lightseagreen.svg) ![](./badges/vim-8.1-lightseagreen.svg)
* **Package Manager:** ![](./badges/apt-2.0.9-lightseagreen.svg) ![](./badges/conda-4.12.0-lightseagreen.svg) ![](./badges/dpkg-1.19.7-lightseagreen.svg) ![](./badges/npm-6.14.4-lightseagreen.svg) ![](./badges/pip-22.3-lightseagreen.svg)
* **Programming Language:** ![](./badges/GCC-9.4.0-lightseagreen.svg) ![](./badges/OpenJDK-1.8.0-lightseagreen.svg) ![](./badges/Python-3.9.10-lightseagreen.svg) ![](./badges/Python-2.7.18-lightseagreen.svg) ![](./badges/R-4.1.3-lightseagreen.svg) ![](./badges/Scala-2.12.15-lightseagreen.svg)
* **Database:** ![](./badges/SQLite-3.39.4-lightseagreen.svg)

:::

::: {tab-item} 3.1.3

[![](badges/release-3.1.3-blue.svg)](https://cloud.sdu.dk/app/jobs/create?app=spark-cluster&version=3.1.3)
[![type](badges/type-interactive-yellow.svg)](interactive_apps.md)
![access](badges/access-open-green.svg)
* **Operating System:** ![](./badges/Ubuntu-20.04-lightseagreen.svg)
* **Shell:** ![](./badges/bash-5.0.17-lightseagreen.svg)
* **Editor:** ![](./badges/emacs-26.3-lightseagreen.svg) ![](./badges/nano-4.8-lightseagreen.svg) ![](./badges/vim-8.1-lightseagreen.svg)
* **Package Manager:** ![](./badges/apt-2.0.9-lightseagreen.svg) ![](./badges/conda-4.10.3-lightseagreen.svg) ![](./badges/dpkg-1.19.7-lightseagreen.svg) ![](./badges/npm-6.14.4-lightseagreen.svg) ![](./badges/pip-22.2.2-lightseagreen.svg)
* **Programming Language:** ![](./badges/GCC-9.4.0-lightseagreen.svg) ![](./badges/OpenJDK-1.8.0-lightseagreen.svg) ![](./badges/Python-3.9.6-lightseagreen.svg) ![](./badges/Python-2.7.18-lightseagreen.svg) ![](./badges/Scala-2.12.10-lightseagreen.svg)
* **Database:** ![](./badges/SQLite-3.36.0-lightseagreen.svg)

:::

::: {tab-item} 3.0.0

[![](badges/release-3.0.0-blue.svg)](https://cloud.sdu.dk/app/jobs/create?app=spark-cluster&version=3.0.0-1)
[![type](badges/type-interactive-yellow.svg)](interactive_apps.md)
![access](badges/access-open-green.svg)
* **Operating System:** ![](./badges/Ubuntu-18.04-lightseagreen.svg)
* **Shell:** ![](./badges/bash-4.4.20-lightseagreen.svg)
* **Editor:** ![](./badges/vim-8.0-lightseagreen.svg)
* **Package Manager:** ![](./badges/apt-1.6.12-lightseagreen.svg) ![](./badges/conda-4.8.3-lightseagreen.svg) ![](./badges/dpkg-1.19.0.5-lightseagreen.svg) ![](./badges/pip-20.2.2-lightseagreen.svg)
* **Programming Language:** ![](./badges/GCC-7.5.0-lightseagreen.svg) ![](./badges/OpenJDK-11.0.8-lightseagreen.svg) ![](./badges/Python-3.7.8-lightseagreen.svg) ![](./badges/Scala-2.12.10-lightseagreen.svg)
* **Database:** ![](./badges/SQLite-3.33.0-lightseagreen.svg)

:::

::: {tab-item} 2.4.5

[![](badges/release-2.4.5-blue.svg)](https://cloud.sdu.dk/app/jobs/create?app=spark-cluster&version=2.4.5-11)
[![type](badges/type-interactive-yellow.svg)](interactive_apps.md)
![access](badges/access-open-green.svg)
* **Operating System:** ![](./badges/Ubuntu-18.04-lightseagreen.svg)
* **Shell:** ![](./badges/bash-4.4.19-lightseagreen.svg)
* **Editor:** ![](./badges/vim-8.0-lightseagreen.svg)
* **Package Manager:** ![](./badges/apt-1.6.11-lightseagreen.svg) ![](./badges/conda-4.8.3-lightseagreen.svg) ![](./badges/dpkg-1.19.0.5-lightseagreen.svg) ![](./badges/pip-20.0.2-lightseagreen.svg)
* **Programming Language:** ![](./badges/GCC-7.5.0-lightseagreen.svg) ![](./badges/OpenJDK-1.8.0-lightseagreen.svg) ![](./badges/Python-3.7.4-lightseagreen.svg) ![](./badges/Scala-2.11.12-lightseagreen.svg)
* **Database:** ![](./badges/SQLite-3.31.1-lightseagreen.svg)

:::

::::

This application deploys a [Spark standalone cluster](https://spark.apache.org/docs/latest/spark-standalone.html).

## Cluster architecture

<img src="figs/Spark_Standalone_Cluster.png" width="90%" align="center" />

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Apache Spark standalone cluster architecture in client mode

The cluster architecture encompasses one _master_ node (`node1`), which acts as the cluster manager, and one or more _worker_ nodes. By default, one worker always runs on `node1`.
The cluster resources are specified using the parameters *Number of nodes* and *Machine type*.

The _master_ process accepts the applications to be run and schedules the _worker_ resources (available CPU cores and memory) among them. _Worker_ processes execute the job's tasks. Applications are submitted either from the `node1` _terminal interface_ or from another UCloud client app _connected to_ `node1`, which also runs Apache Spark (see, e.g., [JupyterLab](jupyter-lab.md#submit-a-spark-application)). Finally, the Spark _driver_ is the program that creates the `SparkContext`, connecting to the _master_ node.

The standalone Spark cluster supports two deploy modes:

- In `client` mode (default), the Spark driver is launched in the same process as the client that submits the application (see, e.g., the figure above).

- In `cluster` mode the driver is launched from one of the _worker_ processes inside the cluster, and the client process exits as soon as it fulfills its responsibility of submitting the application without waiting for the application to finish.

The deploy mode is specified via the property parameter `spark.submit.deployMode`. The complete list of all application properties available for a Spark standalone cluster is reported [here](https://spark.apache.org/docs/latest/configuration.html#application-properties).

## Monitoring

Information about completed and ongoing Spark applications is accessible via the app _web interface_, by clicking on the button

{{ btn_open_interface }}

### Spark UI

The Spark web user interface (UI) is used to monitor all the applications submitted to the cluster. The _master_ and each _worker_ has its own web UI that shows cluster and job statistics.

For each application the Spark UI includes:

- A list of scheduler stages and tasks.
- A summary of RDD sizes and memory usage.
- Environmental information.
- Information about the running executors.

``` {note}
This information is only available for the duration of the Spark application.
```

### Spark history server

The Spark history logs are saved in `/work/spark_logs`, which is created by default when the job starts. A different directory can be specified using the parameter _Spark history_.

The Spark history server can be accessed by running the following command from the `node1` terminal interface:

```console
$ display_spark_history
```

The history server is accessible _only_ from the `node1` web interface.
<br>

<img src="figs/Spark_history_run.png" alt="drawing" width="100%" align="center">

<br>

``` {note}
If the client runs in another UCloud app, the same logs folder must be mounted on both cluster and client apps.
```

## Import data

The mandatory parameter *Input folder* is used to mount the data directory on all the cluster nodes.

``` {note}
If the client runs in another UCloud app, the same data folder must be mounted on both cluster and client apps.
```

## Initialization

Additional packages may be installed on all the _worker_ nodes using the *Initialization* optional parameter.

For information on how to use this parameter, please refer to the [Initialization - Bash script](../hands-on/init-sh.md), [Initialization - Conda packages](../hands-on/init-conda.md), and [Initialization - pip packages](../hands-on/init-pip.md) section of the documentation.

``` {note}
The same packages must be installed on a client node *connected to* the Spark cluster.
```

## Run in batch mode

The parameter _Batch processing_ is used to submit Spark applications via a Bash script, running on the _master_ node.

``` {note}
The job is terminated after the script is executed, independently of the script exit status.
```
